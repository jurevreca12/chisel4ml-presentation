{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bc7f35-ea4e-4b6f-a89c-2f5c8e99d9dd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "val path = System.getProperty(\"user.dir\") + \"/source/load-ivy.sc\"\n",
    "interp.load.module(ammonite.ops.Path(java.nio.file.FileSystems.getDefault().getPath(path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "035ef929",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mchisel3._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mchisel3.util._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mchisel3.iotesters.{ChiselFlatSpec, Driver, PeekPokeTester}\u001b[39m"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import chisel3._\n",
    "import chisel3.util._\n",
    "import chisel3.iotesters.{ChiselFlatSpec, Driver, PeekPokeTester}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d4cc58-3aa2-43c7-b3d5-b82b7e7caf63",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "<h1 style=\"text-align: center;\">Chisel4ml: Generating Fast Implementations of Deeply Quantized Neural Networks using Chisel Generators</h1>\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"slike/e7-logo.png\" width=30%>\n",
    "</div>\n",
    "\n",
    "\n",
    "<h3 style=\"text-align: center;\">Jure Vreƒça</h3>\n",
    "<h4 style=\"text-align: center;\">jure.vreca@ijs.si</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0580eaf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Chisel\n",
    "* Constructing Hardware in a Scala Embedded Language\n",
    "* Chisel is not HLS.\n",
    "* Hardware graph construction during execution.\n",
    "* Chisel is a type-safe meta-programming language for synchronous digital logic design:\n",
    "    * Parametrized types\n",
    "    * Object-oriented programming\n",
    "    * Functional programming\n",
    "    * Static type checking\n",
    "\n",
    "Note: Some of the slides and material were taken from: https://github.com/freechipsproject/chisel-bootcamp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db8e764",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Example\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"slike/FIR_diagram.png\" width=75%>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a7c9b4-9ced-4b1e-8d7c-c03716fa86b4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": []
   },
   "source": [
    "The diagram shows a simple FIR filter that outputs a moving average of the inputs. The z1 and z2 wires are outputs from the registers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d747314",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MovingAverage3(bitWidth: Int) extends Module {\n",
    "  val io = IO(new Bundle {\n",
    "    val in = Input(UInt(bitWidth.W))\n",
    "    val out = Output(UInt(bitWidth.W))\n",
    "  })\n",
    "  val z1 = RegNext(io.in) // Create a register whose input is connected to the argument io.in\n",
    "  val z2 = RegNext(z1)    // Create a register whose input is connected to the argument z1\n",
    "  io.out := (io.in * 1.U) + (z1 * 1.U) + (z2 * 1.U) // `1.U` is an unsigned literal with value 1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a219f683-d4f6-46e1-b9af-d9e894fbd267",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": []
   },
   "source": [
    "- This code shows how to describe the previously shown circuit in Chisel HCL.\n",
    "- Every hardware module in chisel must inherit from the Chisel class Module.\n",
    "- Next, we define the input-output interface using the IO command.\n",
    "- The RegNext function creates a register, where the input to the register is the argument, and the result represents the output of the register.\n",
    "- Thus we define two registers with RegNext and connect them to z1 and z2.\n",
    "- After that we simply compute the output in a straithforward fashion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4299e14",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "visualize(() => new MovingAverage3(8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb24f5f-0d6f-4d7e-859d-b47b88cfc501",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": []
   },
   "source": [
    "- We can visualize the resulting hardware with this visualize function.\n",
    "- We can see  that two registers are created, and a plethora of multiplication and addition nodes.\n",
    "- The clock and reset are implicit, however, they can also be made explicit, if desired. For example if working with multiple clock domains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a9d14a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "//print(getFirrtl(new MovingAverage3(8)))\n",
    "print(getVerilog(new MovingAverage3(8)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407385eb-6160-499e-b754-76e6061317d5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": []
   },
   "source": [
    "- We can also print the Verilog and FIRRTL representation of the circuit.\n",
    "- FIRRTL is an intermeddiate representation used by chisels backend\n",
    "- As you can see the Verilog is not particularly readable, and also has a tree of if-defs.\n",
    "- The FIRRTL representation looks a bit nicer in , and is very similar to Verilog."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e3b711",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# FIR Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d81e513",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "// Generalized FIR filter parameterized by the convolution coefficients\n",
    "class FirFilter(bitWidth: Int, coeffs: Seq[UInt]) extends Module {\n",
    "  val io = IO(new Bundle {\n",
    "    val in = Input(UInt(bitWidth.W))\n",
    "    val out = Output(UInt())\n",
    "  })\n",
    "  // Create the serial-in, parallel-out shift register\n",
    "  val zs = Reg(Vec(coeffs.length, UInt(bitWidth.W)))\n",
    "  zs(0) := io.in\n",
    "  for (i <- 1 until coeffs.length) {\n",
    "    zs(i) := zs(i-1)\n",
    "  }\n",
    "\n",
    "  // Do the multiplies\n",
    "  val products = VecInit.tabulate(coeffs.length)(i => zs(i) * coeffs(i))\n",
    "\n",
    "  // Sum up the products\n",
    "  io.out := products.reduce(_ +& _)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49feac5c-1804-4490-95ff-1a6cca6f4589",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": []
   },
   "source": [
    "- The chisel code for the MovingAverage filter shown before is somewhat similar to equivalent code in Verilog or VHDL.\n",
    "- A more appropriate usage of Chisel is to create generators that are reusable.\n",
    "- This code snippet shows how to create a generalized implementation of a FIR filter in Chisel, where the coefficients are a parameters of the class.\n",
    "- I will not discuss this code in detail, but in essence it uses Scalas functional paradigms to create the hardware in a concise fashion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96f5263",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "// same 3-point moving average filter as before\n",
    "visualize(() => new FirFilter(8, Seq(1.U, 1.U, 1.U)))\n",
    "\n",
    "// 1-cycle delay as a FIR filter\n",
    "//visualize(() => new FirFilter(8, Seq(0.U, 1.U)))\n",
    "\n",
    "// 5-point FIR filter with a triangle impulse response\n",
    "//visualize(() => new FirFilter(8, Seq(1.U, 2.U, 3.U, 2.U, 1.U)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8159fe18-5fda-464c-9b32-4aebc2fd37cc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": []
   },
   "source": [
    "- The code shown on the previous slide generates the exact same hardware, when appropriate input coffecients are given.\n",
    "- For example, if we input 1, 1, 1, then we get the exact same circuit we did before.\n",
    "- We can also get cycle delay filter, or a more complicated 5-point triangle impulse response filter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f3c768-6056-4b06-b5eb-0438e8547b72",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Artificial Neural Networks\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"slike/neuron.drawio.png\" width=45%>\n",
    "</div>\n",
    "<h1 style=\"text-align: center;\">\n",
    "$$\n",
    "\\displaystyle y=f(b + \\sum_{i=0}^{N-1} x_i \\cdot w_i) = f(b + \\vec{x} \\cdot \\vec{w})\n",
    "$$\n",
    "</h1>\n",
    "<h1 style=\"text-align: center;\">\n",
    "$$\n",
    "\\displaystyle y_q = f(b_q + \\frac{\\vec{x_q} \\cdot \\vec{w_q}}{S})\n",
    "$$\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f41cf1-735a-4912-8472-d5c02c1da462",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": []
   },
   "source": [
    "- Lets now move on to artificial neural network models.\n",
    "- In brief, ANNs are in the simple case composed by a set of layer, most whom are computed by neurons connected in specitic patterns.\n",
    "- The figure above shows an example of an artificial neuron model.\n",
    "- x zero through N-1 represent the input vector, w reperesent the weight vectors, b is the bias value and y is the scalar output.\n",
    "- So to compute a neuron we peform a dot product between the input and weight vectors and add the bias.\n",
    "- The attained value is called the pre-activation and is input to a non-linear activation function f which computes the output of the neuron."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53284caf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# How does chisel4ml use Chisel?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e43a50",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def neuron[I <: Bits,\n",
    "           W <: Bits,\n",
    "           M <: Bits,\n",
    "           A <: Bits,\n",
    "           O <: Bits](in: Seq[I],\n",
    "                      weights: Seq[W],\n",
    "                      thresh: A,\n",
    "                      mul: (I, W) => M,\n",
    "                      add: Vec[M] => A,\n",
    "                      actFn: (A, A) => O,\n",
    "                      shift: Int): O = {\n",
    "    val muls = VecInit((in zip weights).map{\n",
    "        case (a,b) => mul(a,b)\n",
    "    })\n",
    "    val pAct = add(muls)\n",
    "    val sAct = (pAct << shift.abs).asTypeOf(pAct)\n",
    "    actFn(sAct, thresh)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a8650d-2cb4-4fec-b540-7788449271c4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": []
   },
   "source": [
    "- So how does chisel4ml create neurons?\n",
    "- This is done by creating a parameterized implementation of a neuron.\n",
    "- The neuron is parameterized by the input, weight and output type.\n",
    "- It takes a sequence of inputs and weights, and a threshold value, which is the inverse of the bias value.\n",
    "- It also takes as parmeter three functions for multiplication, addition and the activation function.\n",
    "- This creates a neuron implementation that is completly generic to the quantization scheme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a75307",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mulUQ(i: SInt, w: SInt): SInt = i * w    // Uniform quantization\n",
    "def addUQ = (x: Vec[SInt]) => x.reduceTree(_ +& _)\n",
    "\n",
    "def mulBW = (i: SInt, w: Bool) => Mux(w, i, -i)  // Binary weight quantization\n",
    "\n",
    "def mulBNN(i: Bool, w: Bool): Bool = ~(i ^ w) // Binarized quantization\n",
    "def addBNN = (x: Vec[Bool]) => PopCount(x.asUInt)\n",
    "\n",
    "def reluFn(act: SInt, thresh: SInt): UInt = Mux((act - thresh) > 0.S, (act - thresh).asUInt, 0.U)\n",
    "def signFn(act:UInt, thresh: UInt): Bool = act >= thresh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a561cb07-0d65-4ccd-81ea-2ac638e86c8e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": []
   },
   "source": [
    "- This slide shows the multiplications and addition function that are input to the neuron function.\n",
    "- The first functions mulUQ and addUQ, show a typicall case where weights are signed integers of arbitrary bitwidths.\n",
    "- The second multiplication function is for binary-weight quantization. In this scheme the neuron weights are binary, but the inputs are not.\n",
    "- At the most extreme level of quantization there exists binarized neural networks, that have both inputs and weights binary. In this case the multiplication is tranformed into the XNOR operation, and the addition is transformed into the population count operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02530dcd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DummyUniformModule extends Module {\n",
    "  val io = IO(new Bundle {\n",
    "    val in = Input(Vec(3, SInt(4.W)))\n",
    "    val out = Output(UInt())\n",
    "  })\n",
    "    io.out := neuron[SInt, SInt, SInt, SInt, UInt](in = io.in,\n",
    "                                                   weights = Seq(1.S, -2.S, 3.S),\n",
    "                                                   thresh = -1.S,\n",
    "                                                   mul = mulUQ,\n",
    "                                                   add = addUQ,\n",
    "                                                   actFn = reluFn,\n",
    "                                                   shift = 1\n",
    "                                                 )\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240f8339-75f7-4cd6-babf-34ae2c63efcd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": []
   },
   "source": [
    "- This slide shows an example usage of the neuron function where the module has 3 4-bit inputs and a single output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f69252",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "visualize(() => new DummyUniformModule())\n",
    "//print(getFirrtl(new DummyUniformModule()))\n",
    "//print(getVerilog(new DummyUniformModule()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0ba6c9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DummyBinarizedModule extends Module {\n",
    "  val io = IO(new Bundle {\n",
    "    val in = Input(Vec(3, Bool()))\n",
    "    val out = Output(UInt())\n",
    "  })\n",
    "    io.out := neuron[Bool, Bool, Bool, UInt, Bool](in = io.in,\n",
    "                                                  weights = Seq(true.B, false.B, true.B),\n",
    "                                                  thresh = 2.U,\n",
    "                                                  mul = mulBNN,\n",
    "                                                  add = addBNN,\n",
    "                                                  actFn = signFn,\n",
    "                                                  shift = 0\n",
    "                                                 )\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a2c0c8-a81e-435d-ae94-1e1ae8bcb90b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": []
   },
   "source": [
    "- We can create a similar module with a binarized neuron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d51f21a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "visualize(() => new DummyBinarizedModule())\n",
    "print(getFirrtl(new DummyBinarizedModule()))\n",
    "//print(getVerilog(new DummyBinarizedModule()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87640e1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "source": [
    "## Other abstractions in Chisel4ml:\n",
    "* ProcessingElement == layer\n",
    "* ProcessingPipeline == model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340b06e0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "source": [
    "<p align=\"center\">\n",
    "<img src=\"slike/ProcElementC4ml.png\" width=450  height=400 align=left>\n",
    "<img src=\"slike/ProcPipelineC4ml.png\" width=450 height=400 align=right>\n",
    "</p>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
