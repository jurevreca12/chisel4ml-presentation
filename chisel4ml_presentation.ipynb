{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1089535-599c-4c6c-8092-050b5a21d3a4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Chisel4ml - high-level software architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5480e5fc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<img src=\"slike/chisel4ml_architecture.png\" align=\"center\" width=55%>\n",
    "\n",
    "Image from _vreca et.al.: Generating Direct Logic Circuit Implementations of Deeply Quantized Neural Networks Using Chisel4ml_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3181427-743a-4009-a3ab-78295cef0836",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": []
   },
   "source": [
    "- Here we have a high-level overview of the chisel4ml architecture.\n",
    "- It has a python frontend and a chisel backend.\n",
    "- The Python frontend can consume quantized neural networks in the form of QKeras or QONNX models. These are two formats for serializing such neural networks.\n",
    "- The python frontend transforms the model description to an internal format called Low-Bitwidth Intermediate Representation or LBIR.\n",
    "- LBIR describes the quantized neural network, and is sent to the chisel backend where the circuit is generated.\n",
    "- The circuit can then be simulated from python, or the verilog files can be packaged into the desired directory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ebd188",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# chisel4ml - Train a model in Brevitas (PyTorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a03f4e9-9a91-434e-b4a9-60eab1f052fc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import chisel4ml\n",
    "from lhc_model import get_lhc_jets_model\n",
    "from lhc_data import get_lhc_dataset\n",
    "from train import train_model, eval_model\n",
    "import torch\n",
    "from brevitas.export import export_qonnx\n",
    "from qonnx.util.cleanup import cleanup_model\n",
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "from server import create_server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64a4bae-4be3-47ce-ae99-384305bed93d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "brevitas_model = get_lhc_jets_model(bitwidth=4)\n",
    "train_loader, test_loader = get_lhc_dataset(batch_size=512)\n",
    "train_model(\n",
    "        model=brevitas_model,\n",
    "        train_loader=train_loader,\n",
    "        criterion=torch.nn.CrossEntropyLoss(),\n",
    "        optimizer=torch.optim.Adam(brevitas_model.parameters(), lr=0.001),\n",
    "        epochs=1,\n",
    "        device='cpu',\n",
    "        prune_rate=0.5,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea92fc42-0491-4bdc-90be-07021955f2e5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": []
   },
   "source": [
    "- I want to know show case how to train and deploy a model.\n",
    "- We train a simple 4-layer fully-connected model for a single epoch on the hls4ml dataset of high-pT jets from simulations of LHC proton-proton collisions.\n",
    "- The performance of this model will be terrible, but this exact topology can be used for effective triggering, if we train for a higher number of epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efeec98-0569-49d3-a484-a69d25b2c4fe",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Evaluate train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7243389a-8c22-4d43-9429-fe2e6367b68a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "eval_model(brevitas_model, test_loader, 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b091af-4d0c-4372-ab11-d3b2f158854d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": []
   },
   "source": [
    "- We can now evaluate the model on the test data set.\n",
    "- As expected, we get terrible performance, more or less random.\n",
    "- However, if we trained the training parameters this would be better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9bd0cf-3d78-48ab-bb8b-a24305412f05",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Export the model to QONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af1bc19-4331-42c6-843d-8100fab532f6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "qonnx_proto = export_qonnx(brevitas_model, torch.randn(brevitas_model.ishape))\n",
    "qonnx_model = ModelWrapper(qonnx_proto)\n",
    "qonnx_model = cleanup_model(qonnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa618420-2e4d-46bc-973f-efe51d37306b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import IPython\n",
    "import netron\n",
    "\n",
    "qonnx_model.save('model.onnx')\n",
    "addr = 'localhost'\n",
    "port = 5555\n",
    "netron.start('model.onnx', (addr, port), browse=False)\n",
    "IPython.display.IFrame(f'http://{addr}:{port}', width=1200, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9e4e59-6478-4222-9df4-faeaca1c22f3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": []
   },
   "source": [
    "- The Brevitas library is based on PyTorch, and it can export the model as a QONNX model.\n",
    "- QONNX is a quantization extension for the Open Neural Network eXchange standard.\n",
    "- This model can be visualized as shown."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276a7633-42c7-43c1-9598-8cac3230f794",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Create chisel4ml circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed04231-b7d9-4b76-844e-2f4c16ac8bd8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from chisel4ml.transform import qonnx_to_lbir\n",
    "from chisel4ml import generate\n",
    "\n",
    "lbir_model = qonnx_to_lbir(qonnx_model)\n",
    "accelerators = generate.accelerators(\n",
    "    lbir_model,\n",
    "    minimize=\"delay\",\n",
    ")\n",
    "c4ml_server, c4ml_subp = create_server(\"/c4ml/chisel4ml.jar\")\n",
    "circuit = generate.circuit(\n",
    "    accelerators,\n",
    "    lbir_model,\n",
    "    use_verilator=True,\n",
    "    gen_timeout_sec=9000,\n",
    "    server=c4ml_server,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425aff38-6af0-4fb7-b671-becd57a23a1c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": []
   },
   "source": [
    "- The QONNX model is input to the chisel4ml python frontend.\n",
    "- It is tranformed into LBIR.\n",
    "- We then create a chisel backend server.\n",
    "- And then send the LBIR model to the chisel backend.\n",
    "- This then generates the firrtl and verilog code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049a458e-e28f-4c06-96bf-774f41fb06dd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# RTL simulation of the circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc635a5-cf6a-4987-b307-d5c6adbc5c4b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "res = circuit(np.zeros(16))\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e7286f-339a-4969-a422-61282f26b774",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "- This circuit can then be simulated from python.\n",
    "- It uses verilator in the background to perform the RTL simulation.\n",
    "- The result is a Numpy array and in this case it is just all zeros, because we haven't trained the model enough."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7502019",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Comparison with hls4ml\n",
    "\n",
    "\n",
    "<img src=\"slike/experiment.png\" width=80% align=center>\n",
    "\n",
    "The results are from our paper For more info see _vreca et.al.: Generating Direct Logic Circuit Implementations of Deeply Quantized Neural Networks Using Chisel4ml_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa67ccfa-765c-4b33-b39a-6e9da10009e5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": []
   },
   "source": [
    "- This figure shows the experiment structure for comparing the chisel4ml results to hls4ml results on the most parallel setting.\n",
    "- We train the models with brevitas and transformed them to QONNX. This model is then input to chisel4ml and hls4ml, which then use Xilinx tools 2023.1 to perform the synthesis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f340c98-f87f-4902-b87d-596d81abc357",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Convolutional neural networks with different bitwidth of quantization - hls4ml vs chisel4ml\n",
    "<p align=\"center\">\n",
    "    <img src=\"slike/lut_plot.png\" width=400  height=400 align=left>\n",
    "    <img src=\"slike/delay_plot.png\" width=400  height=400 align=center>\n",
    "    <img src=\"slike/syn_time_plot.png\" width=400 height=400 align=right>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0cb65c-1553-4602-af26-5a2204b5f7f2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": []
   },
   "source": [
    "- These are results for a generic convolutional neural network trained on the MNIST dataset.\n",
    "- The left most figure shows the number of look-up tables required for implementation, the center shows the path-delay and the right most the total generation time from qonnx model to synthesized Verilog.\n",
    "- The blue line is chisel4ml and orange is hls4ml.\n",
    "- As you can see chisel4ml creates circuits with lower consumption of lookup tables, compared to hls4ml on the fully-parallel setting.\n",
    "- The other results are that chisel4ml generation time is orders of magnitude smaller, and the path delay is higher.\n",
    "- However, the path delay can easily be mitigated by inserting additional pipeline legisters, and then use retiming. This can be easily adjusted, so this result could fairly easily be corrected.\n",
    "- chisel4ml is currently limited to only maximum parallelism. So the direct-circuit implementation of neural networks. Hls4ml allows the designer to choose a tradeoff between amount of parllelism and thus circuit size, and performance requirements. So chisel4ml is a good choice for users who have ultra-low latency requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f805e089-4c49-4270-a20b-4b264e0085bb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Thank you for your attention\n",
    "\n",
    "\n",
    "The authors acknowledge the financial support from the Slovenian Research and Innovation\n",
    "Agency under grant: No. P2-0098. This work is also part of projects that are funded by the ECSEL\n",
    "Joint Undertaking under grant agreement No 101007273 (DAIS) and by the Chips Joint Undertaking\n",
    "under grant agreement No 101139892 (EdgeAI-Trust)."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
